{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c46c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np # Version 1.20.1\n",
    "import pandas as pd # Version 1.2.4\n",
    "# Pandas settings\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('ticks')\n",
    "# Please reduce \"DPI\" values below if plots take too long to display \n",
    "# Higher values make plots remain clear when zoomed in\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "# The lowest recommended value is 200 for A4 size print legibility \n",
    "# The recommended value is 600 for 'photograph-like' legibility\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# Time Series imports\n",
    "import datetime as dt # Version 2.8.1\n",
    "\n",
    "# Pre-Processing imports\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipe\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline as pipe\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "# Modelling imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, plot_roc_curve, precision_recall_fscore_support,  roc_auc_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d38df",
   "metadata": {},
   "source": [
    "## Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83906b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions go here\n",
    "# Time lag column creator\n",
    "def timelag_col_creator(df, columns, timelag_range):\n",
    "    for col in columns:\n",
    "        for num in range(1,timelag_range+1):\n",
    "            df[col+'_lag'+str(num)] = df[col].shift(num)\n",
    "            \n",
    "# Rolling mean column creator\n",
    "def rollmean_col_creator(df, columns, window_num):\n",
    "    for col in columns:\n",
    "        df['Weekly_'+col] = df[col].rolling(window=window_num).mean()\n",
    "# Might be able to do away with roll mean function as it's not used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc587b59",
   "metadata": {},
   "source": [
    "### Time-lag Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61ee542",
   "metadata": {},
   "source": [
    "Considering in our earlier EDA, we discovered some semblance of seasonality in some of the variables, which indicate that values logged at time (t) may very likely be affected by previous values (t-1,t-2...). As data in the `train` dataset is recorded at a weekly frequency, we will create time-lag features for 4 weeks, allowing us to capture the monthly trends. Before doing so, we should create weekly rolling averages for some of these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a8e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial creation of time-lag features based on selected subset of variables, with reference to correlation matrix\n",
    "# cols_to_roll_mean = ['Tavg','WetBulb','Daylight_Hours','StnPressure','AvgSpeed','Wet_NoWet']\n",
    "# rollmean_col_creator(weather, cols_to_roll_mean, 7)\n",
    "# cols_to_time_lag = ['Weekly_Tavg','Weekly_WetBulb','Weekly_Daylight_Hours','Weekly_StnPressure','Weekly_AvgSpeed','Weekly_Wet_NoWet']\n",
    "# timelag_col_creator(weather, cols_to_time_lag, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# & SMOTE\n",
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368cb9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "spray_cleaned = pd.read_csv('../data/spray_cleaned.csv')\n",
    "train_cleaned = pd.read_csv('../data/train_cleaned.csv', parse_dates = ['Date'])\n",
    "weather_cleaned = pd.read_csv('../data/weather_clean.csv', parse_dates = ['Date'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
